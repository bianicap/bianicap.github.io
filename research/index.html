<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="research" content="Bianicap.GitHub.io : ">

    <link rel="stylesheet" type="text/css" media="screen" href="../stylesheets/stylesheet.css">

    <title>Bianica Pires</title>
</head>
	<!-- This is a comment, by the way -->
		

<body>
	
<!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <a id="forkme_banner" href="https://github.com/bianicap">View on GitHub</a>

          <h1 id="project_title">Bianica Pires</h1>
          <h2 id="project_tagline"></h2>
        
        </header>
    </div>
	
    <nav>
    		
        		&nbsp;<a href="../"><br>Home</a>
        		&nbsp; &nbsp; <a href="../research">Research</a>
        		&nbsp; &nbsp; <a href="../PIres_CV_20160701.pdf">CV</a>
        		&nbsp; &nbsp; <a href="../contact">Contact</a>
    		
		</nav>
		
		 <img align="left" src="../IMG_3121.JPG" width="250" height="250" />


    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
   	<h1>Research Interests</h1>
	
	   <p>My research interests involve understanding and exploring complex social systems using computational methods, including 
	    agent-based modeling (ABM), social network analysis (SNA), and geographic information systems (GIS) to model human movement 
	    and behavior.
	
	<h2>Integration of ABM, SNA, and GIS</h2>
	      
	      <p> The integration of SNA and GIS in an ABM allows us to model agent-to-agent and
agent-to-environment interactions spatiotemporally. Moreover, it allows us to explore how social structures
(i.e., dynamic social networks) emerge from individual interactions over social (SNA) and physical
(GIS) space and examine the feedback loop between individual interaction and collective dynamics.
		      
	<h2>The Balance Between Theory and Data</h2>
	      <p>A unique advantage of computational modeling and agent-based modeling, specifically, is its ability to concurrently 
		      build theoretical and empirical models of social phenomena (Manson et al., 2012). 
		      Using a computational approach we can
		      develop “intermediate” models of social phenomena, which are 
		      explanatory in their intent to explore theory and descriptive in their use of empirical data to build the 
		      environment and create the agents. Intermediate models are flexible enough to apply general theories 
		      of human behavior and to test existing theory on environments that represent actual, real world 
		      settings. As such, 
		      they seek a balance between abstraction and reality. This balance provides a certain level 
		      of exploratory flexibility, but at the same time, grounds the model in reality. 
		      
		      Agent-based models can range from stylized “toy” models that represent some caricature of reality to fully 
		      calibrated models that demonstrate quantitative agreement with micro-level processes (Axtell and Epstein, 1994; 
		      Parker et al., 2003; Crooks et al., 2008). In between these two extremes we can develop models that are 
		      explanatory in their intent to explore theory and descriptive in their use of empirical data to build 
		      the environment and create the agents. When talking about theory we must distinguish between the testing of 
		      theory in model results as through “what if” scenarios and the application of theory in guiding model development. 
		      Using ABM, we can test current theory, theoretical assumptions, and empirical findings. While ABMs are ideal for 
		      this type of “what if” analysis, many theories are more internal in nature (e.g., social identity theory). That is, 
		      they have more to do with individuals’ decision-making process and thus must be considered as part of the development 
		      of the agents’ cognitive model. Implementing theory into a computational framework, however, is not trivial as it 
		      was likely not designed for computer code. “Fitting” theory into the agents’ cognition may be operationalized 
		      through an existing conceptual framework (e.g., PECS, BDI). Moreover, the integration of ABMs with social network 
		      analysis (SNA) allows us to structure and quantify the agents’ communication networks, allowing us to simulate for 
		      example, the diffusion of a rumor, social influence through networks, and the sharing of knowledge across an 
		      organization. Theoretically- and empirically-grounded ABMs that I have developed or are in the process of developing 
		      include a simulation of the emergence of riots in a Kenyan informal settlement (Pires and Crooks, 2017), a model of 
		      the 10 year resource-driven war in Sierra Leone (Pires and Crooks, 2016), and a simulation of attitude formation and 
		      knowledge sharing through an organization (PI for the Early Career Army Research Institute Grant #W911NF-16-1-0574).

		      
		      <!--The figure below illustrates
		      how different classication schemes 

The development of these models is facilated through the integration of ABM with SNA and GIS. 
		      
		      
		      
		<p>According to Axtell and Epstein (1994), this range can be described through four classification
			levels. These include Level 0 models, which represent a simple caricature of reality, Level 1
			models, which seek macro-level qualitative agreement with empirical structures, Level 2 models,
			which seek macro-level quantitative agreement with empirical data, and Level 3 models, which seek 
			micro-level quantitative agreement with empirical data. Parker et al. (2003), on the other
			hand, describes this range via an explanatory (i.e., applies some abstraction of reality) to descriptive
			(i.e., based on empirical details of the social phenomena) continuum. Similarly, Crooks and
			Castle (2012) developed a matrix categorized into four areas depending on whether the agents
			and/or the environment are designed (i.e., explanatory) or analyzed (i.e., descriptive). The purpose of the model, a
			rough placement of Axtell and Epstein’s (1994) classification scheme, and the verification and validation
			approach is shown in Figure 1 based on where the model fits in relation to the explanatory
			to descriptive spectrum.
		  
		
			<img align="left" src="../exploratory_to_descriptive.pdf" width="250" height="250" />
			    -->
			
	<h2>Working with "All" Data</h2>
	      <p>An important theme in my postdoc research has been the utility of applying "all" data,including administrative, 
		      opportunity, and survey data, to issues in the social world. These projects have covered a diverse range of 
		      applications, from industrial innovation to environmental issues.  Moreover, due to the human component 
		      inherent in studying social problems, the data used to develop these models has frequently been unstructured, 
		      incomplete, and messy. As such, these data often need to be re-purposed as they were not collected for research 
		      purposes. In a project for Proctor \& Gamble to evaluate their supply chain we were provided with vast amounts o
		      f data from very disparate data sources, including customer orders, production runs, and shipments. 
		      I took a disciplined approach to repurposing these data and developed a “data model.” The data model 
		      involves all steps between data collection and modeling, including the initial screening of the data collected, 
		      the cleaning and restructuring of the data for the project’s purposes, and the understanding of the 
		      relationships and linkages between data tables. Because of the disparate nature of these data, linking 
		      it end-to-end posed a challenge. For instance, customer orders did not link directly to production runs. 
		      By assuming a “first-in, first-out” method, I simulated each shipment back to a production run, and 
		      subsequently, a customer order. For the first time, P&G had a model for which they could link supply 
		      chain data from orders to shipments. An expanded version of the data model has now been applied to several 
		      other projects within the lab. Empirically driven research I have performed include developing discrete-event 
		      simulations to model the supply chain of a P&G manufacturing site; coupling a synthetic population of the 
		      nearly 5 million residents of Houston to a spatiotemporal air quality model to get individual exposure levels 
		      to ozone; using SNA to analyze spatiotemporal event data from the Colombian conflict; and performing 
		      comparative analysis of administrative and survey data for the U.S. Census Bureau. Given the sheer size 
		      of input data, building these models may require the use of big data analytics. For example, I used a 
		      combination of database management technique and high performance computing to integrate the 5 million 
		      synthetic individuals of Houston with 1.2 million activity locations and the hourly ozone data of 47 monitors. 
      </section>
    </div>
	

</body>
	
<!-- FOOTER  -->
  <div id="footer_wrap" class="outer">
   	<footer class="inner">
       	<p>Published with <a href="https://pages.github.com">GitHub Pages</a></p>
     	</footer>
   </div>
	

</html>
